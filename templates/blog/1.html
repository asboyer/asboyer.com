{% extends "layout.html" %}

{% block styles %}
    <link href="/static/css/tmrw_night/prism.css" rel="stylesheet" />
{% endblock %}

{% block content %}
<section class="post">
    <div class="post-header">
        <h2 class="post-title" id="title">
            <strong>Predicting the MVP with Python</strong>
        </h2>

        <h3 class="post-author">
            Andrew Boyer
        </h3>  

        <h3 class="post-date">
            9.10.21
        </h3>  
        
    </div>

<div class="post-content">
<p class="post-text-intro" id="preface">
    My sincerest apologies for my absence on this blog, other things have been eating up my time. Thank you to everyone who supported the <a href="https://asboyer.com/blog/0" target="_blank">last post</a>. <i>Way</i> bigger things are coming soon. Stay tuned for some more posts this month. It is my goal to get a post up every other Monday. Without further ado, on with the highly anticipated story behind <a href="https://goatgrade.com" target="_blank">Goat Grade</a>.
    <br>
    ---
    <br>
    During February of 2021, one year ago, I created a website where I used Python, HTML (no CSS because I was lazy), and data from <a href="https://www.basketball-reference.com/" target="_blank">Basketball Reference</a> to rank NBA players based on their in-game statistics and display my rankings online. After I uploaded it to the internet, I didn't think too much of it. A few months later, the NBA MVP finalists were announced. To my surprise, my algorithm predicted the top <a href="https://www.nba.com/news/kia-mvp-ladder-nikola-jokic-finishes-no-1-among-pack-of-contenders" target="_blank">two front runners</a> in the race for most valuable player. After <a href="https://www.nba.com/kia-mvp/2021-nikola-jokic" target="_blank">Nikola Jokic</a> was announced the league MVP, it became official: a program I wrote in a weekend had predicted which player was going to win MVP months before the finalists were even announced. This is the story of how I built <a href="https://goatgrade.com" target="_blank">Goat Grade</a>, my current plans to improve it, and why my prediction may have actually been a total fluke after all.
</p>

<div class="post-line" style="margin-bottom: 20px"></div>

<h3 class="post-text-header" id="beginnings"><a href="/blog/1#beginnings">Beginnings</a></h3>

<p class="post-text">
    The inspiration behind this project came in multiple ways. I had just finished the first half of my junior year of high school, and was looking for a new project to work on.
    <br>
    Earlier that year, I officially released <a href="https://github.com/asboyer/reporty" target="_blank">Reporty</a>, a Python library designed for organizing and distributing visual data. The library takes data sets or figures that you pass in to it and generates an HTML page with those figures. You also have the option to send that page in an email, and even send it in an embedded email <a class="footnote-link" href="#footnote1" id="footlink1">[1]</a>. After things were slowing down for this project, I wanted to get started something on new. Building Reporty, with the help of a close friend and mentor <a class="footnote-link" href="#footnote2" id="footlink2">[2]</a>, had given me a solid introduction into the world of <a href="https://en.wikipedia.org/wiki/Data_science#:~:text=Data%20science%20is%20an%20interdisciplinary,broad%20range%20of%20application%20domains." target="_blank">data science</a>. Still, I hadn't quite undertaken a project where I actually organized, cleaned, and modeled data from a real data set. Reporty was about taking figures that were already made with existing (or even fake) data and organizing them into a nice web page that our library generated <a class="footnote-link" href="#footnote3" id="footlink3">[3]</a>.
    <br>
    I contacted a friend from Boise, Idaho <a class="footnote-link" href="#footnote4" id="footlink4">[4]</a>, and asked him if he wanted to collaborate. We didn't have any particular idea of what we wanted to do at first, other than the project obviously had to be cool. We bounced around a few ideas, and lingered on the subject of web scraping, which both of us were mostly unfamiliar with. But, what better way to learn than through a building a project? We zeroed in on scraping basketball statistics, and using that data and an algorithm to generate some kind of fun set of predictions. 
</p>
<br>
<h3 class="post-text-header" id="webscraping"><a href="/blog/1#webscraping">Scraping the data</a></h3>


<p class="post-text">
    Before we talk about how we scraped the statistics, allow me to explain "web scraping" in simple terms. 
    <br>
    As we all know, the Internet contains almost an unlimited amount information. Whether its Chic-Fil-A's hours on Sunday, or the criminally low <em>Cars 2</em> IMDb rating, the information we seek is somewhere on a computer connected to the internet, a simple Google search away. 
    <br>
    But, what if we could automate this process? Is it really possible to write a program to get the <em>Cars 2</em> rating without even leaving your terminal? Could it also alert me anytime the rating changes? The answer to these questions is absolutely, thanks to web scraping, which is simply a technique to automate the process of finding information on a website <a class="footnote-link" href="#footnote5" id="footlink5">[5]</a>.
    <br>
    Okay, so now that we know what web scraping is, <i>how</i> do we actually do it with Python? Thanks to some useful libraries, its quite simple. The following code imports the <a href="https://docs.python.org/3/library/urllib.html" target="_blank">urllib</a> and <a href="https://beautiful-soup-4.readthedocs.io/en/latest/" target="_blank">Beautiful Soup</a> Python modules, opens the website that has the information we want, in this case, <a href="https://www.basketball-reference.com/" target="_blank">Basketball Reference</a>, and parses through the html and finds all values surrounded by table tags. more testing. more testing
    
</p>

<div class="code-block">
<pre><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup

year = 2021
url = "https://www.basketball-reference.com/leagues/NBA_{}_per_game.html".format(year)
html = urlopen(url)
soup = BeautifulSoup(html, 'html.parser')

soup.findAll('tr', limit=2)
headers = [th.getText() for th in soup.findAll('tr', limit=2)[0].findAll('th')]
headers = headers[1:]

rows = soup.findAll('tr')[1:]
</code></pre>
</div>

<div class="code-block">
<pre><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
import json
</code></pre>
</div>

<div class="post-line"></div>


<p class="footnote" id="footnote1">
<a class="footnote-link" href="#footlink1">[1]</a> I am still currently working on Reporty. There may be a blog post in the near future explaining how I built it and what my plans are for the future of the library. Check out our <a href="https://github.com/asboyer/reporty" target="_blank">GitHub</a> and fork the repository if you would like to contribute!
</p>

<br>

<p class="footnote" id="footnote2">
<a class="footnote-link" href="#footlink2">[2]</a> <a href="https://github.com/btengels" target="_blank">btengels</a>
</p>

<br>

<p class="footnote" id="footnote3">
<a class="footnote-link" href="#footlink3">[3]</a> That being said, building <a href="https://github.com/asboyer/reporty" target="_blank">Reporty</a> taught me a lot about Python modules, image encoding and sending automated emails. Again, blog post on this project soon.
</p>

<br>
<p class="footnote" id="footnote4">
<a class="footnote-link" href="#footlink4">[4]</a> <a href="https://github.com/kadebaxter" target="_blank">kadebaxter</a>
</p>
<br>

<p class="footnote" id="footnote5">
<a href="#footlink5">[5]</a> Yes, I do acknowledge there are other ways of getting information from websites. A lot of apps actually have APIs, which make things a lot easier when you want to automate the process of collecting data and information. The before mentioned IMDb problem can easily be solved with the <a href="https://imdbpy.readthedocs.io/en/latest/" target="_blank">IMDb python library</a>, which uses the IMDb API. This is what I use for my website's <a href="/movies" target="_blank">movies</a> section. I can get titles, ratings, posters, and more with just a simple Python function. I'll probably post a short tutorial on how to use my favorite APIs in the future.
</p>
</div>



</section> 
{% endblock %}

{% block scripts %}
<script src="/static/js/tmrw_night/prism.js"></script>
{% endblock %}
