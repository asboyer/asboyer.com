{% extends "layout.html" %}

{% block styles %}
    <link href="/static/css/tmrw_night/prism.css" rel="stylesheet" />
{% endblock %}

{% block content %}
<section class="post">
    <div class="post-header">
        <h2 class="post-title" id="title">
            <strong>Predicting the MVP with Python</strong>
        </h2>

        <h3 class="post-author">
            Andrew Boyer
        </h3>  

        <h3 class="post-date">
            9.10.21
        </h3>  
        
    </div>

<div class="post-content">
<p class="post-text-intro" id="preface">
    During February of 2021, I created a website called <a href="https://goatgrade.com" target="_blank">Goat Grade</a>. It used Python, HTML (no CSS because I was lazy), and data from <a href="https://www.basketball-reference.com/" target="_blank">Basketball Reference</a> to rank NBA players based on their in-game statistics and display my rankings online. After I uploaded it to the internet, I didn't think too much of it. A few months later, the NBA MVP finalists were announced. To my surprise, my algorithm predicted the top <a href="https://www.nba.com/news/kia-mvp-ladder-nikola-jokic-finishes-no-1-among-pack-of-contenders" target="_blank">two front runners</a> in the race for most valuable player. After <a href="https://www.nba.com/kia-mvp/2021-nikola-jokic" target="_blank">Nikola Jokic</a> was announced the league MVP, it became official: a program I wrote in a weekend had predicted which player was going to win MVP months before the finalists were even announced. This is the story of how I built <a href="https://goatgrade.com" target="_blank">Goat Grade</a>, my current plans to improve it, and why my prediction may have actually been a total fluke after all.
    Also, sorry its been a while since you've heard from me.
    Bot Testing
</p>

<div class="post-line" style="margin-bottom: 20px"></div>

<h3 class="post-text-header" id="beginnings">Beginnings</h3>

<p class="post-text">
    The inspiration behind this project came in multiple ways. I had just finished the first half of my junior year of high school, and was looking for a new project to work on.
    <br>
    Earlier that year, I officially released <a href="https://github.com/asboyer/reporty" target="_blank">Reporty</a>, a Python library designed for organizing and distributing visual data. The library takes data sets or figures that you pass in to it and generates an HTML page with those figures. You also have the option to send that page in an email, and even send it in an embedded email <a class="footnote-link" href="#footnote1" id="footlink1">[1]</a>. After things were slowing down for this project, I wanted to get started something on new. Building Reporty, with the help of a close friend and mentor <a class="footnote-link" href="#footnote2" id="footlink2">[2]</a>, had given me a solid introduction into the world of <a href="https://en.wikipedia.org/wiki/Data_science#:~:text=Data%20science%20is%20an%20interdisciplinary,broad%20range%20of%20application%20domains." target="_blank">data science</a>. Still, I hadn't quite undertaken a project where I actually organized, cleaned, and modeled data from a real data set. Reporty was about taking figures that were already made with existing (or even fake) data and organizing them into a nice web page that our library generated <a class="footnote-link" href="#footnote3" id="footlink3">[3]</a>.
    <br>
    I contacted a friend from Boise <a class="footnote-link" href="#footnote4" id="footlink4">[4]</a>, and asked him if he wanted to collaborate. We didn't have any particular idea of what we wanted to do at first, other than the project obviously had to be cool. We bounced around a few ideas, and lingered on the subject of web scraping, which both of us were mostly unfamiliar with. But, what better way to learn than through a building a project? We zeroed in on scraping basketball statistics, and using that data and an algorithm to generate some kind of fun prediction. 
</p>
<br>
<h3 class="post-text-header" id="beginnings">Web scraping</h3>

<p class="post-text">
    Before we talk about how we scraped the statistics, allow me to explain web scraping in simple terms. 
    <br>
    As we all know, the Internet contains almost an unlimited amount information. Whether its Chic-Fil-A's hours on Sunday, or the criminally low <em>Cars 2</em> IMDB rating, the information we seek is somewhere on a computer connected to the internet, a simple Google search away. 
    <br>
    But, what if we could automate this process? Is it really possible write a program to get the <em>Cars 2</em> rating without even leaving your terminal? Could it also alert me anytime the rating changes? The answer to all of these questions is yes with web scraping, which is simply just automating the process of finding information on a website. [MORE WEBSCRAPING EXPLANATION]
    <br>
    Yes, I do acknowledge there are other ways of getting information from your terminal. A lot of sites actually have APIs, which make things a lot easier when you want to automate the process of collecting data and information. The before mentioned IMDB problem can easily be solved with the imdb [GET LINK] Python library, which is what I use for my website's <a href="/movies">movies</a> section. I can get titles, ratings, posters, and more with just a simple API call.
<div class="code-block">
<pre><code class="language-python">import imdb
        
ia = imdb.IMDb()
id = '1216475'
rating = ia.get_movie(id).data['rating']
</code></pre>
</div>
</p>

<div class="code-block">
<pre><code class="language-python">from urllib.request import urlopen
from bs4 import BeautifulSoup
import json
</code></pre>
</div>

<div class="post-line"></div>


<p class="footnote" id="footnote1">
<a class="footnote-link" href="#footlink1">[1]</a> I am still currently working on Reporty. There may be a blog post in the near future explaining how I built it and what my plans are for the future of the library. Check out our <a href="https://github.com/asboyer/reporty" target="_blank">GitHub</a> and fork the repository if you would like to contribute!
</p>

<br>

<p class="footnote" id="footnote2">
<a class="footnote-link" href="#footlink2">[2]</a> <a href="https://github.com/btengels" target="_blank">btengels</a>
</p>

<br>

<p class="footnote" id="footnote3">
<a class="footnote-link" href="#footlink3">[3]</a> That being said, building <a href="https://github.com/asboyer/reporty" target="_blank">Reporty</a> taught me a lot about Python modules, image encoding and sending automated emails. Again, blog post on this project soon.
</p>

<br>
<p class="footnote" id="footnote4">
<a class="footnote-link" href="#footlink4">[4]</a> <a href="https://github.com/kadebaxter" target="_blank">kadebaxter</a>
</p>
</div>



</section> 
{% endblock %}

{% block scripts %}
<script src="/static/js/tmrw_night/prism.js"></script>
{% endblock %}
